{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Human Activity Recognition Using WiFi Signals\n",
        "\n",
        "## Overview\n",
        "Human Activity Recognition (HAR) using WiFi signals leverages the unique properties of wireless channel variations to detect different activities.\n",
        "\n",
        "## Data Format\n",
        "- **WiFi signal data** is similar to image data in structure, represented in the shape `(channels, height, width)`, but with a different interpretation:\n",
        "  - `channels` → **channel**\n",
        "  - `height` → **Time Steps**\n",
        "  - `width` → **Antenna Pairs (transmitter-receiver combinations)**\n",
        "- **Labels** represent a predefined set of classes, as is typical in classification tasks."
      ],
      "metadata": {
        "id": "0NnOoFtyHilj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Data"
      ],
      "metadata": {
        "id": "1GqPqJNJIWNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code will only execute\n",
        "# successfully when compression is complete\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alihabibullah/question-2-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnmdeTv2xPQ2",
        "outputId": "4dfa9e6a-cf3b-42f1-dfaf-7c51fb451865"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alihabibullah/question-2-data?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 204M/204M [00:01<00:00, 114MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/alihabibullah/question-2-data/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8hne08gxqjN",
        "outputId": "e7ec2030-e721-41ca-cfe1-fccab672a26d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WiFiSensingDataset.pt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oEZvoIOGxqWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DwIkG1iHVPg",
        "outputId": "87ba768c-594c-424d-f33f-7b0cd40c8030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4d2815cbd2c7>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(f\"{path}/WiFiSensingDataset.pt\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Load the .pt file\n",
        "data = torch.load(f\"{path}/WiFiSensingDataset.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "gKv4rUCekmwu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Analyze the Dataset ( Stored in `data`)\n",
        "\n",
        "1. **Determine the number of unique labels** in the dataset.  \n",
        "\n",
        "2. **Determine the shape of the input data** (number of samples and features).  \n",
        "\n",
        "3. **Find the maximum value** in the dataset.  \n",
        "\n",
        "4. **Find the minimum value** in the dataset.  "
      ],
      "metadata": {
        "id": "8vkoyStvJBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.keys())"
      ],
      "metadata": {
        "id": "4oN-6aro6Q4d",
        "outputId": "41f073d0-73b2-42a3-d672-a16871d645cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['X_test', 'X_train', 'y_test', 'y_train'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = data['y_train']\n",
        "y_test = data['y_test']"
      ],
      "metadata": {
        "id": "NPodI6dC6cV8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data['X_train']\n",
        "X_test = data['X_test']"
      ],
      "metadata": {
        "id": "dFu75CCF62x4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = torch.cat((y_train, y_test), dim=0)\n",
        "\n",
        "unique_labels = torch.unique(all_labels)\n",
        "\n",
        "num_unique_labels = len(unique_labels)\n",
        "print(f\"Number of unique labels: {num_unique_labels}\")"
      ],
      "metadata": {
        "id": "Nkv0JF5l6a5P",
        "outputId": "8840f9e0-ab26-4ea0-de08-32d17d5448d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "HMcmaQHi7dRh",
        "outputId": "9fb88927-4fc5-4ee7-92f9-486b4d8ff091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: torch.Size([2500, 1, 250, 90])\n",
            "Shape of X_test: torch.Size([500, 1, 250, 90])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find the maximum value in the dataset."
      ],
      "metadata": {
        "id": "XO302QBA7sZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_value = torch.max(torch.cat((X_train, X_test), dim=0))\n",
        "print(f\"Maximum value in the dataset: {max_value}\")"
      ],
      "metadata": {
        "id": "iY7wJeXF7r7G",
        "outputId": "1405b3aa-56f2-4925-861a-d44c2cf63e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value in the dataset: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find the minimum value in the dataset."
      ],
      "metadata": {
        "id": "8PC2-j6Q7v6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_value = torch.min(torch.cat((X_train, X_test), dim=0))\n",
        "print(f\"Minimum value in the dataset: {min_value}\")"
      ],
      "metadata": {
        "id": "dbkHkTtB70Wm",
        "outputId": "69b32263-00df-475b-bab4-c89c3db301f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value in the dataset: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Build and Evaluate a Neural Network\n",
        "\n",
        "1. **Design a Neural Network (Maximum 5 Layers)**  \n",
        "   Build a compact neural network with no more than 5 layers. Clearly specify the type of each layer (e.g., Dense, Conv2D) and any activation functions used.\n",
        "\n",
        "2. **Evaluate Your Model**  \n",
        "   Train your network on the provided dataset and report the evaluation metrics (e.g., accuracy, loss). Discuss the performance of your model and any challenges faced during training.\n"
      ],
      "metadata": {
        "id": "zbbW9TqJJI84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 62 * 22, 128)\n",
        "        self.fc2 = nn.Linear(128, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "\n",
        "\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "\n",
        "\n",
        "        x = x.view(-1, 64 * 62 * 22)\n",
        "\n",
        "\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "hci0PeriJIGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7750aa22-5994-4c74-93a1-010d96d786d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=87296, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to tensor\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)  # Ensure labels are of type long\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create datasets from tensors\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "MAMgZ-FXJIL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abaf16da-2a51-4a02-ef9c-549159e7bf9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-ddb5c37401e7>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train = torch.tensor(y_train, dtype=torch.long)  # Ensure labels are of type long\n",
            "<ipython-input-22-ddb5c37401e7>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test = torch.tensor(y_test, dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "5PHWz6VtLLT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d696824-9caa-4a2a-9e9b-8b854e5a3753"
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Loss: 0.8302, Accuracy: 71.28%\n",
            "Epoch [2/3], Loss: 0.7090, Accuracy: 74.96%\n",
            "Epoch [3/3], Loss: 0.6101, Accuracy: 79.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good luck in the exam x)\n",
        "\n",
        "Prepared by: Ahmed Y. Radwan\n"
      ],
      "metadata": {
        "id": "6pqoK28DLPB4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5er_pdi8w5cV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}